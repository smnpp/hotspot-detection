{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "latex"
    }
   },
   "source": [
    "# Data Mining project: Discover and describe areas of interest and events from geo-located data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Dataset and Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pandas to deal with the data\n",
    "import pandas as pd\n",
    "# plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'user', 'lat', 'long', 'tags', 'title', 'date_taken_minute',\n",
      "       'date_taken_hour', 'date_taken_day', 'date_taken_month',\n",
      "       'date_taken_year', 'date_upload_minute', 'date_upload_hour',\n",
      "       'date_upload_day', 'date_upload_month', 'date_upload_year',\n",
      "       'Unnamed: 16', 'Unnamed: 17', 'Unnamed: 18'],\n",
      "      dtype='object')\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 420240 entries, 0 to 420239\n",
      "Data columns (total 19 columns):\n",
      " #   Column              Non-Null Count   Dtype  \n",
      "---  ------              --------------   -----  \n",
      " 0   id                  420240 non-null  int64  \n",
      " 1   user                420240 non-null  object \n",
      " 2   lat                 420240 non-null  float64\n",
      " 3   long                420240 non-null  float64\n",
      " 4   tags                316730 non-null  object \n",
      " 5   title               381911 non-null  object \n",
      " 6   date_taken_minute   420239 non-null  float64\n",
      " 7   date_taken_hour     420240 non-null  int64  \n",
      " 8   date_taken_day      420240 non-null  int64  \n",
      " 9   date_taken_month    420240 non-null  int64  \n",
      " 10  date_taken_year     420240 non-null  int64  \n",
      " 11  date_upload_minute  420228 non-null  object \n",
      " 12  date_upload_hour    420238 non-null  object \n",
      " 13  date_upload_day     420238 non-null  float64\n",
      " 14  date_upload_month   420240 non-null  int64  \n",
      " 15  date_upload_year    420239 non-null  float64\n",
      " 16  Unnamed: 16         142 non-null     float64\n",
      " 17  Unnamed: 17         0 non-null       float64\n",
      " 18  Unnamed: 18         2 non-null       float64\n",
      "dtypes: float64(8), int64(6), object(5)\n",
      "memory usage: 60.9+ MB\n",
      "None\n",
      "                 id            lat           long  date_taken_minute  \\\n",
      "count  4.202400e+05  420240.000000  420240.000000      420239.000000   \n",
      "mean   2.002697e+10      45.768173       4.839672          30.068559   \n",
      "std    1.411384e+10       0.028575       0.031619          39.880117   \n",
      "min    3.066675e+08      45.655200       4.720312           0.000000   \n",
      "25%    7.094503e+09      45.757613       4.826202          14.000000   \n",
      "50%    1.548087e+10      45.763152       4.832183          30.000000   \n",
      "75%    3.145886e+10      45.773509       4.846558          45.000000   \n",
      "max    4.914809e+10      45.854950       5.006709        2019.000000   \n",
      "\n",
      "       date_taken_hour  date_taken_day  date_taken_month  date_taken_year  \\\n",
      "count    420240.000000   420240.000000     420240.000000    420240.000000   \n",
      "mean         14.746695       15.456813          7.000493      2013.294256   \n",
      "std           6.583236        9.637870          4.611831        37.141359   \n",
      "min           0.000000        1.000000          1.000000         1.000000   \n",
      "25%          12.000000        8.000000          4.000000      2012.000000   \n",
      "50%          15.000000       15.000000          7.000000      2014.000000   \n",
      "75%          18.000000       23.000000         10.000000      2017.000000   \n",
      "max        2013.000000     2013.000000       2011.000000      2238.000000   \n",
      "\n",
      "       date_upload_day  date_upload_month  date_upload_year  Unnamed: 16  \\\n",
      "count    420238.000000      420240.000000     420239.000000   142.000000   \n",
      "mean         16.398738           6.698277       2013.648624  1958.880282   \n",
      "std           8.450967           4.672163         37.006109   331.444924   \n",
      "min           0.000000           1.000000          1.000000    12.000000   \n",
      "25%           9.000000           4.000000       2012.000000  2013.000000   \n",
      "50%          17.000000           7.000000       2014.000000  2016.000000   \n",
      "75%          24.000000          10.000000       2017.000000  2016.000000   \n",
      "max          31.000000        2011.000000       2019.000000  2019.000000   \n",
      "\n",
      "       Unnamed: 17  Unnamed: 18  \n",
      "count          0.0          2.0  \n",
      "mean           NaN       2012.0  \n",
      "std            NaN          0.0  \n",
      "min            NaN       2012.0  \n",
      "25%            NaN       2012.0  \n",
      "50%            NaN       2012.0  \n",
      "75%            NaN       2012.0  \n",
      "max            NaN       2012.0  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>user</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>tags</th>\n",
       "      <th>title</th>\n",
       "      <th>date_taken_minute</th>\n",
       "      <th>date_taken_hour</th>\n",
       "      <th>date_taken_day</th>\n",
       "      <th>date_taken_month</th>\n",
       "      <th>date_taken_year</th>\n",
       "      <th>date_upload_minute</th>\n",
       "      <th>date_upload_hour</th>\n",
       "      <th>date_upload_day</th>\n",
       "      <th>date_upload_month</th>\n",
       "      <th>date_upload_year</th>\n",
       "      <th>Unnamed: 16</th>\n",
       "      <th>Unnamed: 17</th>\n",
       "      <th>Unnamed: 18</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4395181099</td>\n",
       "      <td>30624617@N03</td>\n",
       "      <td>45.754858</td>\n",
       "      <td>4.821710</td>\n",
       "      <td>chair,lyon,rhône,chaise,rhônealpes</td>\n",
       "      <td>Chaises avec vue</td>\n",
       "      <td>11.0</td>\n",
       "      <td>15</td>\n",
       "      <td>28</td>\n",
       "      <td>2</td>\n",
       "      <td>2010</td>\n",
       "      <td>23</td>\n",
       "      <td>20</td>\n",
       "      <td>28.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4394748717</td>\n",
       "      <td>35853470@N00</td>\n",
       "      <td>45.753270</td>\n",
       "      <td>4.862953</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>51.0</td>\n",
       "      <td>17</td>\n",
       "      <td>28</td>\n",
       "      <td>2</td>\n",
       "      <td>2010</td>\n",
       "      <td>52</td>\n",
       "      <td>17</td>\n",
       "      <td>28.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4394694699</td>\n",
       "      <td>11817998@N05</td>\n",
       "      <td>45.760655</td>\n",
       "      <td>4.846564</td>\n",
       "      <td>365,iphone</td>\n",
       "      <td>59/365 - R46 V103 B163</td>\n",
       "      <td>29.0</td>\n",
       "      <td>17</td>\n",
       "      <td>28</td>\n",
       "      <td>2</td>\n",
       "      <td>2010</td>\n",
       "      <td>33</td>\n",
       "      <td>17</td>\n",
       "      <td>28.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4394803790</td>\n",
       "      <td>11545749@N06</td>\n",
       "      <td>45.784000</td>\n",
       "      <td>4.874072</td>\n",
       "      <td>nin,nineinchnails,gift,screening,toiou,avott</td>\n",
       "      <td>2010-01-29 Toiou Avott Lyon</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>2010</td>\n",
       "      <td>38</td>\n",
       "      <td>12</td>\n",
       "      <td>28.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4394803554</td>\n",
       "      <td>11545749@N06</td>\n",
       "      <td>45.784000</td>\n",
       "      <td>4.874072</td>\n",
       "      <td>lyon,nin,nineinchnails,gift,screening,toiou,avott</td>\n",
       "      <td>2010-01-28 Toiou Avott Lyon</td>\n",
       "      <td>10.0</td>\n",
       "      <td>20</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>2010</td>\n",
       "      <td>38</td>\n",
       "      <td>12</td>\n",
       "      <td>28.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id          user        lat      long  \\\n",
       "0  4395181099  30624617@N03  45.754858  4.821710   \n",
       "1  4394748717  35853470@N00  45.753270  4.862953   \n",
       "2  4394694699  11817998@N05  45.760655  4.846564   \n",
       "3  4394803790  11545749@N06  45.784000  4.874072   \n",
       "4  4394803554  11545749@N06  45.784000  4.874072   \n",
       "\n",
       "                                                tags  \\\n",
       "0                 chair,lyon,rhône,chaise,rhônealpes   \n",
       "1                                                NaN   \n",
       "2                                         365,iphone   \n",
       "3       nin,nineinchnails,gift,screening,toiou,avott   \n",
       "4  lyon,nin,nineinchnails,gift,screening,toiou,avott   \n",
       "\n",
       "                         title  date_taken_minute  date_taken_hour  \\\n",
       "0             Chaises avec vue               11.0               15   \n",
       "1                          NaN               51.0               17   \n",
       "2       59/365 - R46 V103 B163               29.0               17   \n",
       "3  2010-01-29 Toiou Avott Lyon               15.0               20   \n",
       "4  2010-01-28 Toiou Avott Lyon               10.0               20   \n",
       "\n",
       "   date_taken_day  date_taken_month  date_taken_year date_upload_minute  \\\n",
       "0              28                 2             2010                 23   \n",
       "1              28                 2             2010                 52   \n",
       "2              28                 2             2010                 33   \n",
       "3              28                 1             2010                 38   \n",
       "4              28                 1             2010                 38   \n",
       "\n",
       "  date_upload_hour  date_upload_day  date_upload_month  date_upload_year  \\\n",
       "0               20             28.0                  2            2010.0   \n",
       "1               17             28.0                  2            2010.0   \n",
       "2               17             28.0                  2            2010.0   \n",
       "3               12             28.0                  2            2010.0   \n",
       "4               12             28.0                  2            2010.0   \n",
       "\n",
       "   Unnamed: 16  Unnamed: 17  Unnamed: 18  \n",
       "0          NaN          NaN          NaN  \n",
       "1          NaN          NaN          NaN  \n",
       "2          NaN          NaN          NaN  \n",
       "3          NaN          NaN          NaN  \n",
       "4          NaN          NaN          NaN  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data from table file where entries are separated with a space\n",
    "data = pd.read_table(\"flickr_data2.csv\", sep=\",\", low_memory=False)\n",
    "\n",
    "data.columns = data.columns.str.strip()\n",
    "\n",
    "print(data.columns)\n",
    "print(data.info())\n",
    "print(data.describe())\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform Exploratory Data Analysis\n",
    "First, we will explore the most common **data quality issues**:\n",
    "* missing-vals\n",
    "* duplicates\n",
    "\n",
    "Second, we will use [**descriptive statistics**](#desc-stats) to have get a statistical summary of the data. \n",
    "\n",
    "We will then use [**data visualisaiton**](#data-vis) to get a better understanding of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wrong type values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial: 420240\n",
      "id                                                           7387935070\n",
      "user                                                       68256211@N06\n",
      "lat                                                            45.76869\n",
      "long                                                           4.843872\n",
      "tags                  portrait,girl,canon,spring,lyon,parade,fille,p...\n",
      "title                                                    Gay Pride 2012\n",
      "date_taken_minute                                                  58.0\n",
      "date_taken_hour                                                      15\n",
      "date_taken_day                                                       16\n",
      "date_taken_month                                                      6\n",
      "date_taken_year                                                    2012\n",
      "date_upload_minute                                                    2\n",
      "date_upload_hour                                                     20\n",
      "date_upload_day                                                    17.0\n",
      "date_upload_month                                                     6\n",
      "date_upload_year                                                 2012.0\n",
      "Unnamed: 16                                                         NaN\n",
      "Unnamed: 17                                                         NaN\n",
      "Unnamed: 18                                                         NaN\n",
      "Name: 98811, dtype: object\n",
      "id                                                           7387935070\n",
      "user                                                       68256211@N06\n",
      "lat                                                            45.76869\n",
      "long                                                           4.843872\n",
      "tags                  portrait,girl,canon,spring,lyon,parade,fille,p...\n",
      "title                                                    Gay Pride 2012\n",
      "date_taken_minute                                                  58.0\n",
      "date_taken_hour                                                    15.0\n",
      "date_taken_day                                                     16.0\n",
      "date_taken_month                                                    6.0\n",
      "date_taken_year                                                  2012.0\n",
      "date_upload_minute                                                  NaN\n",
      "date_upload_hour                                                    NaN\n",
      "date_upload_day                                                    17.0\n",
      "date_upload_month                                                   6.0\n",
      "date_upload_year                                                 2012.0\n",
      "Unnamed: 16                                                         NaN\n",
      "Unnamed: 17                                                         NaN\n",
      "Unnamed: 18                                                         NaN\n",
      "Name: 98811, dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>user</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>tags</th>\n",
       "      <th>title</th>\n",
       "      <th>date_taken_minute</th>\n",
       "      <th>date_taken_hour</th>\n",
       "      <th>date_taken_day</th>\n",
       "      <th>date_taken_month</th>\n",
       "      <th>date_taken_year</th>\n",
       "      <th>date_upload_minute</th>\n",
       "      <th>date_upload_hour</th>\n",
       "      <th>date_upload_day</th>\n",
       "      <th>date_upload_month</th>\n",
       "      <th>date_upload_year</th>\n",
       "      <th>Unnamed: 16</th>\n",
       "      <th>Unnamed: 17</th>\n",
       "      <th>Unnamed: 18</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4395181099</td>\n",
       "      <td>30624617@N03</td>\n",
       "      <td>45.754858</td>\n",
       "      <td>4.821710</td>\n",
       "      <td>chair,lyon,rhône,chaise,rhônealpes</td>\n",
       "      <td>Chaises avec vue</td>\n",
       "      <td>11.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4394748717</td>\n",
       "      <td>35853470@N00</td>\n",
       "      <td>45.753270</td>\n",
       "      <td>4.862953</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>51.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4394694699</td>\n",
       "      <td>11817998@N05</td>\n",
       "      <td>45.760655</td>\n",
       "      <td>4.846564</td>\n",
       "      <td>365,iphone</td>\n",
       "      <td>59/365 - R46 V103 B163</td>\n",
       "      <td>29.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4394803790</td>\n",
       "      <td>11545749@N06</td>\n",
       "      <td>45.784000</td>\n",
       "      <td>4.874072</td>\n",
       "      <td>nin,nineinchnails,gift,screening,toiou,avott</td>\n",
       "      <td>2010-01-29 Toiou Avott Lyon</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4394803554</td>\n",
       "      <td>11545749@N06</td>\n",
       "      <td>45.784000</td>\n",
       "      <td>4.874072</td>\n",
       "      <td>lyon,nin,nineinchnails,gift,screening,toiou,avott</td>\n",
       "      <td>2010-01-28 Toiou Avott Lyon</td>\n",
       "      <td>10.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id          user        lat      long  \\\n",
       "0  4395181099  30624617@N03  45.754858  4.821710   \n",
       "1  4394748717  35853470@N00  45.753270  4.862953   \n",
       "2  4394694699  11817998@N05  45.760655  4.846564   \n",
       "3  4394803790  11545749@N06  45.784000  4.874072   \n",
       "4  4394803554  11545749@N06  45.784000  4.874072   \n",
       "\n",
       "                                                tags  \\\n",
       "0                 chair,lyon,rhône,chaise,rhônealpes   \n",
       "1                                                NaN   \n",
       "2                                         365,iphone   \n",
       "3       nin,nineinchnails,gift,screening,toiou,avott   \n",
       "4  lyon,nin,nineinchnails,gift,screening,toiou,avott   \n",
       "\n",
       "                         title  date_taken_minute  date_taken_hour  \\\n",
       "0             Chaises avec vue               11.0             15.0   \n",
       "1                          NaN               51.0             17.0   \n",
       "2       59/365 - R46 V103 B163               29.0             17.0   \n",
       "3  2010-01-29 Toiou Avott Lyon               15.0             20.0   \n",
       "4  2010-01-28 Toiou Avott Lyon               10.0             20.0   \n",
       "\n",
       "   date_taken_day  date_taken_month  date_taken_year  date_upload_minute  \\\n",
       "0            28.0               2.0           2010.0                 NaN   \n",
       "1            28.0               2.0           2010.0                 NaN   \n",
       "2            28.0               2.0           2010.0                 NaN   \n",
       "3            28.0               1.0           2010.0                 NaN   \n",
       "4            28.0               1.0           2010.0                 NaN   \n",
       "\n",
       "   date_upload_hour  date_upload_day  date_upload_month  date_upload_year  \\\n",
       "0               NaN             28.0                2.0            2010.0   \n",
       "1               NaN             28.0                2.0            2010.0   \n",
       "2               NaN             28.0                2.0            2010.0   \n",
       "3               NaN             28.0                2.0            2010.0   \n",
       "4               NaN             28.0                2.0            2010.0   \n",
       "\n",
       "   Unnamed: 16  Unnamed: 17  Unnamed: 18  \n",
       "0          NaN          NaN          NaN  \n",
       "1          NaN          NaN          NaN  \n",
       "2          NaN          NaN          NaN  \n",
       "3          NaN          NaN          NaN  \n",
       "4          NaN          NaN          NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Affiche la taille initiale\n",
    "print(f\"Initial: {len(data)}\")\n",
    "print(data.iloc[98811])\n",
    "\n",
    "# Dictionnaire des règles de validation\n",
    "validation_rules = {\n",
    "    'lat': lambda x: pd.api.types.is_number(x) and 45.69804 <= x <= 45.79972,\n",
    "    'long': lambda x: pd.api.types.is_number(x) and 4.76075 <= x <= 4.93901,\n",
    "    'date_taken_minute': lambda x: pd.api.types.is_number(x) and 0 <= x <= 59,\n",
    "    'date_taken_hour': lambda x: pd.api.types.is_number(x) and 0 <= x <= 23,\n",
    "    'date_taken_day': lambda x: pd.api.types.is_number(x) and 1 <= x <= 31,\n",
    "    'date_taken_month': lambda x: pd.api.types.is_number(x) and 1 <= x <= 12,\n",
    "    'date_taken_year': lambda x: pd.api.types.is_number(x) and 1900 <= x <= 2100,\n",
    "    'date_upload_minute': lambda x: pd.api.types.is_number(x) and 0 <= x <= 59,\n",
    "    'date_upload_hour': lambda x: pd.api.types.is_number(x) and 0 <= x <= 23,\n",
    "    'date_upload_day': lambda x: pd.api.types.is_number(x) and 1 <= x <= 31,\n",
    "    'date_upload_month': lambda x: pd.api.types.is_number(x) and 1 <= x <= 12,\n",
    "    'date_upload_year': lambda x: pd.api.types.is_number(x) and 1900 <= x <= 2100,\n",
    "}\n",
    "\n",
    "# Fonction de nettoyage des colonnes\n",
    "def clean_column(dataframe, column_name, validation_func):\n",
    "    dataframe[column_name] = dataframe[column_name].apply(\n",
    "        lambda x: x if validation_func(x) else np.nan\n",
    "    )\n",
    "\n",
    "# Appliquer les règles de validation à chaque colonne\n",
    "for column, rule in validation_rules.items():\n",
    "    if column in data.columns:\n",
    "        clean_column(data, column, rule)\n",
    "\n",
    "print(data.iloc[98811])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing Values\n",
    "\n",
    "To check the missing values, several approaches can be used:\n",
    "\n",
    "1. The `info()` mwthods provides a summary of a dataframe in terms of the types of values, non-null values and memory usage. Thus, by comparing the number of non-null values of each column with the total number of entries, one can have an idea of missing values.\n",
    "2. Using the [`isna()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.isna.html) method. By summing the resulting values, we obtain the number of null values for each column.\n",
    "3. To get the rows with any missing values, you can use `isna()` followed by `any(axis=1)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial: 420240\n",
      "After removing missing values: 355491\n"
     ]
    }
   ],
   "source": [
    "print(f\"Initial: {len(data)}\")\n",
    "# remove rows with missing values on the columns id, lat, and long\n",
    "data_cleaned_missing_values = data.dropna(subset=['id', 'lat', 'long'])\n",
    "print(f\"After removing missing values: {len(data_cleaned_missing_values)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial: 355491\n",
      "213891\n",
      "After removing duplicates: 141596\n"
     ]
    }
   ],
   "source": [
    "# remove duplicates\n",
    "print(f\"Initial: {len(data_cleaned_missing_values)}\")\n",
    "print(data_cleaned_missing_values.duplicated().sum())\n",
    "data_cleaned_duplicates = data_cleaned_missing_values.drop_duplicates(subset=['id', 'lat', 'long'],keep='first')\n",
    "# show the stats\n",
    "print(f\"After removing duplicates: {len(data_cleaned_duplicates)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Descriptive Statistics\n",
    "\n",
    "To obtain the statistical summary of the dataframe, we can use [`describe()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.describe.html). For different columns, it displays the count, the average value, the standard deviation, the min and max values, percentiles. \n",
    "By default, in mixed data types DataFrames, it displays the values for quantative data only:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>date_taken_minute</th>\n",
       "      <th>date_taken_hour</th>\n",
       "      <th>date_taken_day</th>\n",
       "      <th>date_taken_month</th>\n",
       "      <th>date_taken_year</th>\n",
       "      <th>date_upload_minute</th>\n",
       "      <th>date_upload_hour</th>\n",
       "      <th>date_upload_day</th>\n",
       "      <th>date_upload_month</th>\n",
       "      <th>date_upload_year</th>\n",
       "      <th>Unnamed: 16</th>\n",
       "      <th>Unnamed: 17</th>\n",
       "      <th>Unnamed: 18</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.415960e+05</td>\n",
       "      <td>141596.000000</td>\n",
       "      <td>141596.000000</td>\n",
       "      <td>141552.000000</td>\n",
       "      <td>141566.000000</td>\n",
       "      <td>141595.000000</td>\n",
       "      <td>141571.000000</td>\n",
       "      <td>141548.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>141594.000000</td>\n",
       "      <td>141569.000000</td>\n",
       "      <td>141549.000000</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.018108e+10</td>\n",
       "      <td>45.761139</td>\n",
       "      <td>4.836779</td>\n",
       "      <td>29.386063</td>\n",
       "      <td>14.862587</td>\n",
       "      <td>15.091006</td>\n",
       "      <td>7.116387</td>\n",
       "      <td>2014.058065</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.347162</td>\n",
       "      <td>6.852425</td>\n",
       "      <td>2014.419501</td>\n",
       "      <td>1928.086957</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2012.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.373251e+10</td>\n",
       "      <td>0.014849</td>\n",
       "      <td>0.020774</td>\n",
       "      <td>17.450493</td>\n",
       "      <td>4.990502</td>\n",
       "      <td>8.694537</td>\n",
       "      <td>3.406928</td>\n",
       "      <td>3.108261</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.448202</td>\n",
       "      <td>3.505216</td>\n",
       "      <td>2.766905</td>\n",
       "      <td>411.524041</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>3.066675e+08</td>\n",
       "      <td>45.698056</td>\n",
       "      <td>4.760769</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1926.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2009.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2012.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>8.046895e+09</td>\n",
       "      <td>45.757525</td>\n",
       "      <td>4.826516</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2012.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2012.000000</td>\n",
       "      <td>2013.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2012.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.582660e+10</td>\n",
       "      <td>45.762366</td>\n",
       "      <td>4.832997</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>2014.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>2014.000000</td>\n",
       "      <td>2015.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2012.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.148142e+10</td>\n",
       "      <td>45.768595</td>\n",
       "      <td>4.844010</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>2017.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>2017.000000</td>\n",
       "      <td>2016.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2012.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.914809e+10</td>\n",
       "      <td>45.799710</td>\n",
       "      <td>4.938987</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>2019.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>2019.000000</td>\n",
       "      <td>2019.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2012.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id            lat           long  date_taken_minute  \\\n",
       "count  1.415960e+05  141596.000000  141596.000000      141552.000000   \n",
       "mean   2.018108e+10      45.761139       4.836779          29.386063   \n",
       "std    1.373251e+10       0.014849       0.020774          17.450493   \n",
       "min    3.066675e+08      45.698056       4.760769           0.000000   \n",
       "25%    8.046895e+09      45.757525       4.826516          14.000000   \n",
       "50%    1.582660e+10      45.762366       4.832997          29.000000   \n",
       "75%    3.148142e+10      45.768595       4.844010          44.000000   \n",
       "max    4.914809e+10      45.799710       4.938987          59.000000   \n",
       "\n",
       "       date_taken_hour  date_taken_day  date_taken_month  date_taken_year  \\\n",
       "count    141566.000000   141595.000000     141571.000000    141548.000000   \n",
       "mean         14.862587       15.091006          7.116387      2014.058065   \n",
       "std           4.990502        8.694537          3.406928         3.108261   \n",
       "min           0.000000        1.000000          1.000000      1926.000000   \n",
       "25%          12.000000        8.000000          4.000000      2012.000000   \n",
       "50%          15.000000       14.000000          7.000000      2014.000000   \n",
       "75%          18.000000       23.000000         10.000000      2017.000000   \n",
       "max          23.000000       31.000000         12.000000      2019.000000   \n",
       "\n",
       "       date_upload_minute  date_upload_hour  date_upload_day  \\\n",
       "count                 0.0               0.0    141594.000000   \n",
       "mean                  NaN               NaN        15.347162   \n",
       "std                   NaN               NaN         8.448202   \n",
       "min                   NaN               NaN         1.000000   \n",
       "25%                   NaN               NaN         8.000000   \n",
       "50%                   NaN               NaN        15.000000   \n",
       "75%                   NaN               NaN        23.000000   \n",
       "max                   NaN               NaN        31.000000   \n",
       "\n",
       "       date_upload_month  date_upload_year  Unnamed: 16  Unnamed: 17  \\\n",
       "count      141569.000000     141549.000000    46.000000          0.0   \n",
       "mean            6.852425       2014.419501  1928.086957          NaN   \n",
       "std             3.505216          2.766905   411.524041          NaN   \n",
       "min             1.000000       2009.000000    12.000000          NaN   \n",
       "25%             4.000000       2012.000000  2013.000000          NaN   \n",
       "50%             7.000000       2014.000000  2015.000000          NaN   \n",
       "75%            10.000000       2017.000000  2016.000000          NaN   \n",
       "max            12.000000       2019.000000  2019.000000          NaN   \n",
       "\n",
       "       Unnamed: 18  \n",
       "count          1.0  \n",
       "mean        2012.0  \n",
       "std            NaN  \n",
       "min         2012.0  \n",
       "25%         2012.0  \n",
       "50%         2012.0  \n",
       "75%         2012.0  \n",
       "max         2012.0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_cleaned_duplicates.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data for clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we will droping the columns user, tag and title because they are not necessary for geographic clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>date_taken_minute</th>\n",
       "      <th>date_taken_hour</th>\n",
       "      <th>date_taken_day</th>\n",
       "      <th>date_taken_month</th>\n",
       "      <th>date_taken_year</th>\n",
       "      <th>date_upload_minute</th>\n",
       "      <th>date_upload_hour</th>\n",
       "      <th>date_upload_day</th>\n",
       "      <th>date_upload_month</th>\n",
       "      <th>date_upload_year</th>\n",
       "      <th>Unnamed: 16</th>\n",
       "      <th>Unnamed: 17</th>\n",
       "      <th>Unnamed: 18</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4395181099</td>\n",
       "      <td>45.754858</td>\n",
       "      <td>4.821710</td>\n",
       "      <td>11.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4394748717</td>\n",
       "      <td>45.753270</td>\n",
       "      <td>4.862953</td>\n",
       "      <td>51.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4394694699</td>\n",
       "      <td>45.760655</td>\n",
       "      <td>4.846564</td>\n",
       "      <td>29.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4394803790</td>\n",
       "      <td>45.784000</td>\n",
       "      <td>4.874072</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4394803554</td>\n",
       "      <td>45.784000</td>\n",
       "      <td>4.874072</td>\n",
       "      <td>10.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id        lat      long  date_taken_minute  date_taken_hour  \\\n",
       "0  4395181099  45.754858  4.821710               11.0             15.0   \n",
       "1  4394748717  45.753270  4.862953               51.0             17.0   \n",
       "2  4394694699  45.760655  4.846564               29.0             17.0   \n",
       "3  4394803790  45.784000  4.874072               15.0             20.0   \n",
       "4  4394803554  45.784000  4.874072               10.0             20.0   \n",
       "\n",
       "   date_taken_day  date_taken_month  date_taken_year  date_upload_minute  \\\n",
       "0            28.0               2.0           2010.0                 NaN   \n",
       "1            28.0               2.0           2010.0                 NaN   \n",
       "2            28.0               2.0           2010.0                 NaN   \n",
       "3            28.0               1.0           2010.0                 NaN   \n",
       "4            28.0               1.0           2010.0                 NaN   \n",
       "\n",
       "   date_upload_hour  date_upload_day  date_upload_month  date_upload_year  \\\n",
       "0               NaN             28.0                2.0            2010.0   \n",
       "1               NaN             28.0                2.0            2010.0   \n",
       "2               NaN             28.0                2.0            2010.0   \n",
       "3               NaN             28.0                2.0            2010.0   \n",
       "4               NaN             28.0                2.0            2010.0   \n",
       "\n",
       "   Unnamed: 16  Unnamed: 17  Unnamed: 18  \n",
       "0          NaN          NaN          NaN  \n",
       "1          NaN          NaN          NaN  \n",
       "2          NaN          NaN          NaN  \n",
       "3          NaN          NaN          NaN  \n",
       "4          NaN          NaN          NaN  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clustering = data_cleaned_duplicates.drop(columns=['user'])\n",
    "df_clustering = df_clustering.drop(columns=['tags'])\n",
    "df_clustering = df_clustering.drop(columns=['title'])\n",
    "\n",
    "df_clustering.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's apply a [`StandardScaler`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html). Recall, that for a given value `x`, a standard score is given by $z = \\frac{x - mean(\\mathbf{x})}{std(\\mathbf{x})}$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaler\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.14953145 -0.42300291 -0.72538134 ...         nan         nan\n",
      "          nan]\n",
      " [-1.14956294 -0.52994641  1.25994429 ...         nan         nan\n",
      "          nan]\n",
      " [-1.14956687 -0.0326053   0.47102249 ...         nan         nan\n",
      "          nan]\n",
      " ...\n",
      " [ 2.09820947  1.39564253  1.85987915 ...         nan         nan\n",
      "          nan]\n",
      " [ 1.79453936  0.50918336  0.17921433 ...         nan         nan\n",
      "          nan]\n",
      " [ 1.80695534  0.72145406 -0.17637572 ...         nan         nan\n",
      "          nan]]\n",
      "141596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Malte\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\utils\\extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "C:\\Users\\Malte\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\utils\\extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "C:\\Users\\Malte\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\utils\\extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n"
     ]
    }
   ],
   "source": [
    "# Scale the data\n",
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(df_clustering)\n",
    "# show\n",
    "print(scaled_data)\n",
    "# create a DataFrame\n",
    "scaled_data_df = pd.DataFrame(data=scaled_data, columns=df_clustering.columns)\n",
    "scaled_data_df.head()\n",
    "\n",
    "print(len(scaled_data_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hierarchical Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "from sklearn.cluster import AgglomerativeClustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input X contains NaN.\nAgglomerativeClustering does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m linkage_type \u001b[38;5;129;01min\u001b[39;00m linkages:\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;66;03m# Appliquer AgglomerativeClustering\u001b[39;00m\n\u001b[0;32m      4\u001b[0m     cluster \u001b[38;5;241m=\u001b[39m AgglomerativeClustering(n_clusters\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, linkage\u001b[38;5;241m=\u001b[39mlinkage_type)\n\u001b[1;32m----> 5\u001b[0m     cluster_labels \u001b[38;5;241m=\u001b[39m \u001b[43mcluster\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mscaled_data_df\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;66;03m# Calculer le score de silhouette\u001b[39;00m\n\u001b[0;32m      8\u001b[0m     silhouette_avg \u001b[38;5;241m=\u001b[39m silhouette_score(scaled_data_df, cluster_labels)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\cluster\\_agglomerative.py:1129\u001b[0m, in \u001b[0;36mAgglomerativeClustering.fit_predict\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m   1108\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit_predict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m   1109\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Fit and return the result of each sample's clustering assignment.\u001b[39;00m\n\u001b[0;32m   1110\u001b[0m \n\u001b[0;32m   1111\u001b[0m \u001b[38;5;124;03m    In addition to fitting, this method also return the result of the\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1127\u001b[0m \u001b[38;5;124;03m        Cluster labels.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1129\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\base.py:900\u001b[0m, in \u001b[0;36mClusterMixin.fit_predict\u001b[1;34m(self, X, y, **kwargs)\u001b[0m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    878\u001b[0m \u001b[38;5;124;03mPerform clustering on `X` and returns cluster labels.\u001b[39;00m\n\u001b[0;32m    879\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    896\u001b[0m \u001b[38;5;124;03m    Cluster labels.\u001b[39;00m\n\u001b[0;32m    897\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    898\u001b[0m \u001b[38;5;66;03m# non-optimized default implementation; override when a better\u001b[39;00m\n\u001b[0;32m    899\u001b[0m \u001b[38;5;66;03m# method is possible for a given clustering algorithm\u001b[39;00m\n\u001b[1;32m--> 900\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    901\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabels_\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\cluster\\_agglomerative.py:989\u001b[0m, in \u001b[0;36mAgglomerativeClustering.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    970\u001b[0m \u001b[38;5;129m@_fit_context\u001b[39m(prefer_skip_nested_validation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    971\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    972\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Fit the hierarchical clustering from features, or distance matrix.\u001b[39;00m\n\u001b[0;32m    973\u001b[0m \n\u001b[0;32m    974\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    987\u001b[0m \u001b[38;5;124;03m        Returns the fitted instance.\u001b[39;00m\n\u001b[0;32m    988\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 989\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mensure_min_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    990\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit(X)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\base.py:633\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    631\u001b[0m         out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[1;32m--> 633\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    634\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n\u001b[0;32m    635\u001b[0m     out \u001b[38;5;241m=\u001b[39m _check_y(y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\utils\\validation.py:1064\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m   1058\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1059\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m expected <= 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1060\u001b[0m         \u001b[38;5;241m%\u001b[39m (array\u001b[38;5;241m.\u001b[39mndim, estimator_name)\n\u001b[0;32m   1061\u001b[0m     )\n\u001b[0;32m   1063\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m force_all_finite:\n\u001b[1;32m-> 1064\u001b[0m     \u001b[43m_assert_all_finite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1065\u001b[0m \u001b[43m        \u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1066\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1067\u001b[0m \u001b[43m        \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1068\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1069\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1071\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copy:\n\u001b[0;32m   1072\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_numpy_namespace(xp):\n\u001b[0;32m   1073\u001b[0m         \u001b[38;5;66;03m# only make a copy if `array` and `array_orig` may share memory`\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\utils\\validation.py:123\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    120\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m first_pass_isfinite:\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m--> 123\u001b[0m \u001b[43m_assert_all_finite_element_wise\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    124\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    125\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    126\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nan\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    127\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmsg_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmsg_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    128\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    129\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    130\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\utils\\validation.py:172\u001b[0m, in \u001b[0;36m_assert_all_finite_element_wise\u001b[1;34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    155\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m estimator_name \u001b[38;5;129;01mand\u001b[39;00m input_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m has_nan_error:\n\u001b[0;32m    156\u001b[0m     \u001b[38;5;66;03m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[0;32m    157\u001b[0m     \u001b[38;5;66;03m# scikit-learn.\u001b[39;00m\n\u001b[0;32m    158\u001b[0m     msg_err \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    159\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not accept missing values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    160\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    170\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#estimators-that-handle-nan-values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    171\u001b[0m     )\n\u001b[1;32m--> 172\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[1;31mValueError\u001b[0m: Input X contains NaN.\nAgglomerativeClustering does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values"
     ]
    }
   ],
   "source": [
    "linkages = ['complete', 'average', 'single']\n",
    "for linkage_type in linkages:\n",
    "    # Appliquer AgglomerativeClustering\n",
    "    cluster = AgglomerativeClustering(n_clusters=3, linkage=linkage_type)\n",
    "    cluster_labels = cluster.fit_predict(scaled_data_df)\n",
    "\n",
    "    # Calculer le score de silhouette\n",
    "    silhouette_avg = silhouette_score(scaled_data_df, cluster_labels)\n",
    "    print(f\"Silhouette score for {linkage_type} linkage: {silhouette_avg:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
